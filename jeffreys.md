Statistics is practical epistemology. It's unclear why -- short of Meillassoux's argument of ancestrality, which is very worth of careful consideration by each individual person -- any further rationality otaku (not a technical term) would be needed. 

Practical epistemologists are of two minds (and not, as often claimed, of two kinds). On the one hand, the epistemologist understands that knowledge should be derived from the "data", which is a bad latinism for "what is given". Now, what's given to us by the Situation is highly variable; I can see that it's cloudy outside, but in a different day it would have been sunny. This is not particularly vexatory because I know sunny days have existed, and know that as time goes by I'll know many sunny and cloudy days both. I know, to some extent, that should the structure of reality persist, sunny and cloudy days will continue to happen, and as lifetimes go by this extent becomes *intensity* (what's known in the trade as "probability"). But this switch from extent-to-knowledge to intensity-of-knowledge does become vexatory when a pure Humean question is asked: will the sun (covered or not by clouds) rise tomorrow? Since it's never been the case that the sun hasn't risen, it would seem that one can confidently argue "I know this with full intensity, it will". But this isn't a given, it's a contingent claim knowable-to-some-extent; and it's apparently contingent on *nothing* inside the known structure of reality -- therefore, on the structure of reality *itself*. 

On the other hand, the epistemologist knows that he knows things *to some intensity* as well. He intensely (and almost fully) knows that the sun will rise (the precise quantitative intensity has been worked by Laplace). He also knows to some intensity that coin flips should not be *too* biased -- can a coin that passes for a coin be that much heavier on the one side? The lingo is "Bayesian prior", and there's equations to go with it. I don't think we need a fuller exposition here; but the following digression is perhaps the simplest mathematical idea that's extremely useful and unknown to most; you will learn something valuable and also allow me to further compress future discussions.

The name of this concept is *pseudocounts*. It could be called "ballot stuffing", but that's not the traditional name; and implies mischief. In essence, it means that whenever you decide to observe a finite set of states of the world (the simple example is always a coin flip with heads/tails, but we could be watching thousands or millions of possibilities), you should start out by quantitatively expressing the intensive knowledge you already have. I'll give a strange example: if you happen to know that Bayern Munich is four times as strong as its World Championship finals opponent Tigres de MÃ©jico, you should interpret the result as follows:

1) Your "prior probability" (the quantitative expression of the intensive knowledge you have) is 80% or 0.8. This is because it leaves 20% to Tigres and 80% is four times as much as 20%.

2a) If Bayern Munich happens to win, the extent-of-knowledge you have about what's been given to you is: 100% = 1 victory for Bayern. But you have to *add* what you knew to quantify your intensive knowledge: 1+0.8=1.8 for Bayern, 0.2+0=0.2 for Tigres. Therefore: out of (1.8+0.2)=2 points available, 1.8/2 = 90% has gone to Bayern. Tigres has won 10%. 

2b) Let's flip this. If Tigres wins, then Bayern gets 0.8 points out of 2 available = 40%; Tigres gets the remaining 60%. 

Why doesn't Tigres win all the way through? Maybe a Cartesian demon switched the broadcast you saw with deepfakes.

There's way too many technicalities to disclaim here; in technical statistical applications you aren't forced to have priors under 1; you could believe Bayern is stronger with "volume" (usually called "concentration" in the literature) 10, and add 8 full points to it (and 2 to Tigre). Then a victory for Tigres is just 1 point out of possible 10. This gets too complicated when you're just watching cars go by and counting red ones, though, and there's a technical reason to formulate priors as I taught you: the Dirichlet measure underlying these simple calculations has maximum probabilities at 0 or 1 (either Bayern wins or not; it's not a mixed event). I also fudged up the fractions a bit; you're calculating means when modes should be calculated. But shut up already: I'm optimizing for "easy to learn": with this rule and a calculator you can give quantitative expression to the extent to which you know that purple cars have never been in your neighborhood. A purple car is a strange thing; but if you've just moved, maybe you just haven't seen them.

Now, counting cars is a straightforward statistical, i.e. epistemological operation. It's a specific theory of how can you know that purple cars exist. Our main example is, to repeat, strange (a word that descends from the latin for "extraneous", from outside): short of Cartesian demons, it's known (to indefinitely large extent -- you can keep interrogating people as much as you'd like) that one team or the other won. But when have we ever cared about epistemology? The fractional outcomes calculated are, quite literally, *from outside* the entire matter of sports. 


TO BE CONTINUED
